{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4a3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pfb\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cd2d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def A(x):\n",
    "    \"\"\"Applies PFB, irfft's that, flatten.\"\"\"\n",
    "    # Forward PFB the Signal\n",
    "    b = pfb.forward_pfb(x)\n",
    "    # Inverse Fourier Transform along axis=1\n",
    "    b = irfft(b)\n",
    "    # Apply circulant boundary conditions\n",
    "    b = np.concatenate([b, b[:3, :]], axis=0)\n",
    "    return b.flatten()\n",
    "    \n",
    "def A_inv(b_flat, lblock=2048):\n",
    "    \"\"\"Inverse of A. Reshape the array, rfft, iPFB.\"\"\"\n",
    "    # Sanity check\n",
    "    if len(b_flat)/lblock != len(b_flat)//lblock: \n",
    "        raise Exception(\"Dimensions of input do not match lblock!\")\n",
    "    # Reshape array so that it looks like irfft'd pfb output dims\n",
    "    b = b_flat.reshape((-1,lblock))[:-3,:]\n",
    "    # Rfft along axis=1\n",
    "    b = rfft(b)\n",
    "    return pfb.inverse_pfb(b)\n",
    "\n",
    "def A_inv_weiner(b_flat, lblock=2048):\n",
    "    \"\"\"Inverse of A with weiner filtering. Reshape the array, rfft, iPFB with weiner filter.\"\"\"\n",
    "    # Sanity check\n",
    "    if len(b_flat)/lblock != len(b_flat)//lblock: \n",
    "        raise Exception(\"Dimensions of input do not match lblock!\")\n",
    "    # Reshape array so that it looks like irfft'd pfb output dims\n",
    "    b = b_flat.reshape((-1,lblock))[:-3,:]\n",
    "    # Rfft along axis=1\n",
    "    b = rfft(b)\n",
    "    return pfb.inverse_pfb(b, weiner_thresh=0.25)\n",
    "    \n",
    "def A_quantize(x, delta):\n",
    "    \"\"\"Takes signal, pfb's it, quantizes, irfft's that.\"\"\"\n",
    "    # Forward PFB the signal\n",
    "    b = pfb.forward_pfb(x)\n",
    "    # Quantize the filter bank\n",
    "    # The sqrt is to account for the next IRFFT step\n",
    "    b = pfb.quantize(b, np.sqrt(2*(b.shape[1] - 1)) * delta)\n",
    "    # Inverse Fourier Transform\n",
    "    b = irfft(b) # Same as apply along axis=1\n",
    "    # Apply circulant boundary conditions\n",
    "    b = np.concatenate([b, b[:3, :]], axis=0)\n",
    "    return b.flatten() \n",
    "\n",
    "def R(x, lblock):\n",
    "    \"\"\"Rotation matrix?\"\"\"\n",
    "    lx = len(x)\n",
    "    if lx/lblock != lx//lblock: \n",
    "        raise Exception(\"Len x must divide lblock.\")\n",
    "    k = lx // lblock\n",
    "    \"\"\"TBC here...\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7759ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_quantization_error( delta=0.5 , k=80 ):\n",
    "    \"\"\"Simulates and plots the iPFB quantization noise and the noise after correction. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    delta : float\n",
    "        The length of the interval over which quantization noise is uniformly sampled. \n",
    "        The standard deviation of this distribution is delta / root 12. \n",
    "    k : int\n",
    "        The number of blocks to simulate. \n",
    "    \n",
    "    \"\"\"\n",
    "    # Simulated input data is randomly sampled from a normal distribution. \n",
    "    x = np.random.normal(0,1,LBLOCK*k) \n",
    "    \n",
    "    d = A_quantize(x,delta) \n",
    "    # N_inv and Q_inv are diagonal matrices so we store them as 1D-arrays \n",
    "    N_inv = np.ones(len(x)) * 6 / delta**2 \n",
    "\n",
    "    ### 3 percent of original data given as prior \n",
    "    # the noise matrix for the prior \n",
    "    prior_3 = np.zeros(len(x)) # what we know about x, information we saved \n",
    "    prior_3[saved_idxs_3] = pfb.quantize_real(x[saved_idxs_3].copy() , delta) # quantized original signal \n",
    "\n",
    "    Q_inv_3 = np.ones(len(x)) # this is a prior, change to zeros if you want zero for infinite uncertainty\n",
    "#         Q_inv_3 = np.zeros(len(x))\n",
    "    Q_inv_3[saved_idxs_3] = np.ones(len(saved_idxs_3)) * (12 / delta**2) # 8 bits per real number (finer std because no complex) \n",
    "\n",
    "    B_3 = lambda ts: AT(N_inv * A(ts)) + Q_inv_3 * ts # think ts===x\n",
    "    u_3 = AT(N_inv * d) + Q_inv_3 * prior_3 # this is same as mult prior by var=12/delta^2\n",
    "\n",
    "    ### 1 percent of original data given as prior\n",
    "    # the noise matrix for the prior\n",
    "    prior_1 = np.zeros(len(x)) # what we know about x, information we saved\n",
    "    prior_1[saved_idxs_1] = pfb.quantize_real(x[saved_idxs_1].copy() , delta) # quantized original signal\n",
    "\n",
    "    Q_inv_1 = np.zeros(len(x)) \n",
    "    Q_inv_1[saved_idxs_1] = np.ones(len(saved_idxs_1)) * 12 / delta**2 # 8 bits per real number\n",
    "\n",
    "    B_1 = lambda ts: AT(N_inv * A(ts)) + Q_inv_1 * ts # think ts===x\n",
    "    u_1 = AT(N_inv * d) + Q_inv_1 * prior_1\n",
    "\n",
    "    ### Optimize CHI squared using conjugate gradient method\n",
    "    # x0 is the standard IPFB reconstruction\n",
    "    x0 = np.real( A_inv(d) )\n",
    "    x0_weiner = np.real( A_inv_weiner(d) ) # by default the weiner threshold is set to 0.25\n",
    "\n",
    "    # print(\"\\n\\nd={}\".format(d)) # trace, they are indeed real\n",
    "    # print(\"\\n\\nx_0={}\".format(x0)) # complex dtype but zero imag componant\n",
    "\n",
    "#         print(\"\\nConjugate Gradient Descent, with 3% extra data (prior is a quantized 3% of original timestream)\")\n",
    "    if verbose: \n",
    "        plt.figure(figsize=(14,3.5))\n",
    "\n",
    "        # rms virgin pfb\n",
    "        rms_virgin = (x - x0)**2\n",
    "        rms_virgin = np.reshape(rms_virgin[5*LBLOCK:-5*LBLOCK],(k-10,LBLOCK)) # bad practice to hard code k=80...? I just want to write this fast\n",
    "        rms_net_virgin = np.sqrt(np.mean(rms_virgin))\n",
    "        rms_virgin = np.sqrt(np.mean(rms_virgin,axis=0))\n",
    "        rms_virgin = mav(rms_virgin,5)\n",
    "        plt.semilogy(rms_virgin[5:-5],label=\"rmse virgin ipfb\") \n",
    "\n",
    "        # rms weiner filtered pfb\n",
    "        rms_weiner = (x - x0_weiner)**2\n",
    "        rms_weiner = np.reshape(rms_weiner[5*LBLOCK:-5*LBLOCK],(k-10,LBLOCK)) \n",
    "        rms_net_weiner = np.sqrt(np.mean(rms_weiner))\n",
    "        rms_weiner = np.sqrt(np.mean(rms_weiner,axis=0))\n",
    "        plt.semilogy(rms_weiner[5:-5],label=\"rmse weiner filtered\") \n",
    "\n",
    "        plt.grid(which=\"both\") \n",
    "        plt.legend()\n",
    "        plt.title(\"Log IPFB RMS residuals (smoothed)\\nrmse virgin = {:.3f} rmse weiner = {:.3f}\".format(rms_net_virgin,rms_net_weiner),fontsize=16) \n",
    "        plt.xlabel(\"Channel (n)\",fontsize=13)\n",
    "        plt.ylabel(\"RMSE\",fontsize=13)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"Log_virgin_IPFB_RMS_residuals_weiner_{}.png\".format(np.random.randint(2)))\n",
    "        plt.show()\n",
    "        x_out_3 = conjugate_gradient_descent_verbose(B_3,u_3,x,x0=x0_weiner,rmin=0.0,max_iter=10)\n",
    "        # above set rmin to zero for it to just iterate specified amount of times\n",
    "#             input(\"\\nPress [Enter] to proceede\\n\") \n",
    "#         x_out_3 = conjugate_gradient_descent(B_3,u_3,x0=x0_with_zeros,rmin=1000,max_iter=25)\n",
    "#         print(\"\\n\\n-----------------------------------------------------------------------------------------------\")\n",
    "#         print(\"-----------------------------------------------------------------------------------------------\")\n",
    "#         print(\"\\n\\n\\nConjugate Gradient Descent, with 1% extra data (prior is a quantized 1% of original timestream)\")\n",
    "    x_out_1 = conjugate_gradient_descent(B_1,u_1,x0=x0_weiner,rmin=2000,max_iter=35)        \n",
    "    return "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
